[32mINFO    [0m integration.ha_tests.test_upgrade_from_stable:test_upgrade_from_stable.py:102 starting continuous writes to the database
[33mWARNING [0m juju.model:model.py:1563 relate is deprecated and will be removed. Use integrate instead.
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/0 [executing] active: Primary
  postgresql/1 [executing] active: 
  postgresql/2 [executing] active: 
  postgresql-test-app/0 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_upgrade_from_stable:test_upgrade_from_stable.py:106 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.test_upgrade_from_stable:test_upgrade_from_stable.py:115 Build charm locally
[32mINFO    [0m integration.ha_tests.test_upgrade_from_stable:test_upgrade_from_stable.py:118 Refresh the charm
[32mINFO    [0m integration.ha_tests.test_upgrade_from_stable:test_upgrade_from_stable.py:121 Wait for upgrade to start
[32mINFO    [0m integration.ha_tests.test_upgrade_from_stable:test_upgrade_from_stable.py:128 Wait for upgrade to complete
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/0 [idle] active: Primary
  postgresql/1 [executing] waiting: other units upgrading first...
  postgresql/2 [executing] waiting: other units upgrading first...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/0 [executing] active: Primary
  postgresql/1 [executing] active: 
  postgresql/2 [executing] maintenance: updating configuration
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/0 [idle] active: 
  postgresql/1 [idle] active: 
  postgresql/2 [executing] maintenance: refreshing the snap
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/0 [idle] active: 
  postgresql/1 [idle] active: 
  postgresql/2 [executing] maintenance: refreshing the snap
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/0 [idle] waiting: other units upgrading first...
  postgresql/1 [idle] waiting: other units upgrading first...
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/0 [idle] waiting: other units upgrading first...
  postgresql/1 [idle] waiting: other units upgrading first...
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/0 [idle] waiting: other units upgrading first...
  postgresql/1 [idle] waiting: other units upgrading first...
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  postgresql/0 [idle] waiting: other units upgrading first...
  postgresql/1 [idle] waiting: other units upgrading first...
  postgresql/2 [executing] waiting: waiting for database initialisation
[32mINFO    [0m pytest_operator.plugin:plugin.py:903 Model status:

Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.4.5    unsupported  01:53:28Z

App                  Version  Status  Scale  Charm                Channel      Rev  Exposed  Message
postgresql           14.12    active      3  postgresql                          0  no       
postgresql-test-app           active      1  postgresql-test-app  latest/edge  239  no       received database credentials of the first database

Unit                    Workload  Agent      Machine  Public address  Ports     Message
postgresql-test-app/0*  active    idle       3        10.200.48.226             received database credentials of the first database
postgresql/0*           waiting   idle       0        10.200.48.104   5432/tcp  other units upgrading first...
postgresql/1            waiting   idle       1        10.200.48.200   5432/tcp  other units upgrading first...
postgresql/2            waiting   executing  2        10.200.48.114   5432/tcp  waiting for database initialisation

Machine  State    Address        Inst id        Base          AZ  Message
0        started  10.200.48.104  juju-fedee8-0  ubuntu@22.04      Running
1        started  10.200.48.200  juju-fedee8-1  ubuntu@22.04      Running
2        started  10.200.48.114  juju-fedee8-2  ubuntu@22.04      Running
3        started  10.200.48.226  juju-fedee8-3  ubuntu@22.04      Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:909 Juju error logs:

machine-0: 01:35:25 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:35:25 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-0: 01:35:25 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-1: 01:35:25 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:35:25 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-1: 01:35:26 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-3: 01:35:30 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:35:30 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-test-app-0: 01:35:30 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-2: 01:35:31 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:35:31 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-2: 01:35:31 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-postgresql-2: 01:46:22 ERROR unit.postgresql/2.juju-log upgrade:2: replication is not healthy
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 435, in is_replication_healthy
    raise Exception
Exception

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 418, in is_replication_healthy
    for attempt in Retrying(stop=stop_after_delay(60), wait=wait_fixed(3)):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 419, in exc_check
    raise retry_exc from fut.exception()
tenacity.RetryError: RetryError[<Future at 0x7f0a24d46f80 state=finished raised Exception>]
unit-postgresql-2: 01:47:33 ERROR unit.postgresql/2.juju-log upgrade:2: replication is not healthy
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 435, in is_replication_healthy
    raise Exception
Exception

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 418, in is_replication_healthy
    for attempt in Retrying(stop=stop_after_delay(60), wait=wait_fixed(3)):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 419, in exc_check
    raise retry_exc from fut.exception()
tenacity.RetryError: RetryError[<Future at 0x7f0a24d468f0 state=finished raised Exception>]
unit-postgresql-2: 01:48:44 ERROR unit.postgresql/2.juju-log upgrade:2: replication is not healthy
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 435, in is_replication_healthy
    raise Exception
Exception

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 418, in is_replication_healthy
    for attempt in Retrying(stop=stop_after_delay(60), wait=wait_fixed(3)):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 419, in exc_check
    raise retry_exc from fut.exception()
tenacity.RetryError: RetryError[<Future at 0x7f0a24d47c70 state=finished raised Exception>]
unit-postgresql-2: 01:49:56 ERROR unit.postgresql/2.juju-log upgrade:2: replication is not healthy
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 435, in is_replication_healthy
    raise Exception
Exception

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 418, in is_replication_healthy
    for attempt in Retrying(stop=stop_after_delay(60), wait=wait_fixed(3)):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 419, in exc_check
    raise retry_exc from fut.exception()
tenacity.RetryError: RetryError[<Future at 0x7f0a24d11030 state=finished raised Exception>]
unit-postgresql-2: 01:51:07 ERROR unit.postgresql/2.juju-log upgrade:2: replication is not healthy
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 435, in is_replication_healthy
    raise Exception
Exception

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 418, in is_replication_healthy
    for attempt in Retrying(stop=stop_after_delay(60), wait=wait_fixed(3)):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 419, in exc_check
    raise retry_exc from fut.exception()
tenacity.RetryError: RetryError[<Future at 0x7f0a24d46950 state=finished raised Exception>]
unit-postgresql-2: 01:52:24 ERROR unit.postgresql/2.juju-log replication is not healthy
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 435, in is_replication_healthy
    raise Exception
Exception

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/src/cluster.py", line 418, in is_replication_healthy
    for attempt in Retrying(stop=stop_after_delay(60), wait=wait_fixed(3)):
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/var/lib/juju/agents/unit-postgresql-2/charm/venv/tenacity/__init__.py", line 419, in exc_check
    raise retry_exc from fut.exception()
tenacity.RetryError: RetryError[<Future at 0x7f0088a479d0 state=finished raised Exception>]

[32mINFO    [0m pytest_operator.plugin:plugin.py:991 Forgetting model main...